{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic Python modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set(color_codes=True)\n",
    "\n",
    "#Read in csv of cleaned data for the full regression(71 predictors: df1)\n",
    "df = pd.read_csv('Model1.csv')\n",
    "print(df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up variables and scale the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn regression modules\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "#Set up variables: X, y\n",
    "df1= df.drop('drugmort', axis = 1)\n",
    "X = df1.values\n",
    "y = df['drugmort'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import scale\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "# Scale the features\n",
    "X = scale(X)\n",
    "y = scale(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression - full, untransformed, scaled: Model 1 (from R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Create the regressor: reg_all\n",
    "reg_all = LinearRegression()\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "reg_all.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = reg_all.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2 training set: {}\".format(reg_all.score(X_train, y_train)))\n",
    "\n",
    "rmsemod1 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error testing set: {}\".format(rmsemod1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10-Fold cross validation on full, untransformed linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the necessary modules\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# Compute 10-fold cross-validation scores: cv_reg\n",
    "cv_reg = cross_val_score(reg_all, X, y, cv=10)\n",
    "\n",
    "# Print the 10-fold cross-validation scores\n",
    "print(cv_reg)\n",
    "\n",
    "print(\"Average 10-Fold CV Score: {}\".format(np.mean(cv_reg)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression: Full/untransformed data\n",
    "\n",
    "### 1) Determine the best alpha level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_plot(cv_scores, cv_scores_std):\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    ax.plot(alpha_space, cv_scores)\n",
    "\n",
    "    std_error = cv_scores_std / np.sqrt(10)\n",
    "\n",
    "    ax.fill_between(alpha_space, cv_scores + std_error, cv_scores - std_error, alpha=0.2)\n",
    "    ax.set_ylabel('CV Score +/- Std Error')\n",
    "    ax.set_xlabel('Alpha')\n",
    "    ax.axhline(np.max(cv_scores), linestyle='--', color='.5')\n",
    "    ax.set_xlim([alpha_space[0], alpha_space[-1]])\n",
    "    ax.set_xscale('log')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Setup the array of alphas and lists to store scores\n",
    "alpha_space = np.logspace(-4, 0, 50)\n",
    "ridge_scores = []\n",
    "ridge_scores_std = []\n",
    "\n",
    "# Create a ridge regressor: ridge\n",
    "ridge = Ridge(normalize=True)\n",
    "\n",
    "# Compute scores over range of alphas\n",
    "for alpha in alpha_space:\n",
    "\n",
    "    # Specify the alpha value to use: ridge.alpha\n",
    "    ridge.alpha = alpha\n",
    "    \n",
    "    # Perform 10-fold CV: ridge_cv_scores\n",
    "    ridge_cv_scores = cross_val_score(ridge, X, y, cv=10)\n",
    "    \n",
    "    # Append the mean of ridge_cv_scores to ridge_scores\n",
    "    ridge_scores.append(np.mean(ridge_cv_scores))\n",
    "    \n",
    "    # Append the std of ridge_cv_scores to ridge_scores_std\n",
    "    ridge_scores_std.append(np.std(ridge_cv_scores))\n",
    "\n",
    "# Display the plot\n",
    "display_plot(ridge_scores, ridge_scores_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Run Ridge regression on full/untransformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Create the regressor: ridge\n",
    "ridge1 = Ridge(alpha=0.08, normalize=True)\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "ridge1.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = ridge1.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2 training set: {}\".format(ridge1.score(X_train, y_train)))\n",
    "rmse_ridge1 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error testing set: {}\".format(rmse_ridge1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 10-fold cross-validation:  Ridge on full/untransformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 10-fold cross-validation scores: cv_ridge1\n",
    "cv_ridge1 = cross_val_score(ridge1, X, y, cv=10)\n",
    "\n",
    "# Print the 10-fold cross-validation scores\n",
    "print(cv_ridge1)\n",
    "\n",
    "print(\"Average 10-Fold CV Score: {}\".format(np.mean(cv_ridge1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear and Ridge regressions using transformed data (log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in csv of transformed data: dftrans\n",
    "dftrans = pd.read_csv('Model3.csv')\n",
    "print(dftrans.shape)\n",
    "dftrans.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the df for the linear regression: Step, Transformed\n",
    "\n",
    "df35 = dftrans[['drugmort','aamort', 'chmort' , 'infmort' , 'mentdistr' , \n",
    "    'foodins' , 'mvmort' , 'uninsure' , 'chuninsure' , 'disconyouth' , \n",
    "    'homicide' , 'under18' , 'over65' , 'aframer' , 'amerindian' , 'asian' , \n",
    "    'hawaiin' , 'hispanic' , 'rural' , 'lifelost' , 'fairhealth' , 'lowbirth' , \n",
    "    'physinactive' , 'excdrinking' , 'alcoholdrive' , 'chlamydia' , 'unemployed' , \n",
    "    'chpovertyw' , 'X80income' , 'singparent' , 'socialassoc' , 'severehous' , \n",
    "    'commute' , 'new_pcp_ratio' , 'new_mhp_ratio']]\n",
    "print(df35.shape)\n",
    "df35.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up variables and scale the features: Full/transformed, step/transformed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up variables for Full/transformed and Step/transformed: Xft, yft, Xst, yst\n",
    "dftrans2 = dftrans.drop('drugmort', axis = 1)\n",
    "Xft = dftrans2.values\n",
    "yft = dftrans['drugmort'].values\n",
    "\n",
    "df35_2 = df35.drop('drugmort', axis = 1)\n",
    "Xst = df35_2.values\n",
    "yst = df35['drugmort'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features\n",
    "Xft = scale(Xft)\n",
    "yft = scale(yft)\n",
    "\n",
    "Xst = scale(Xst)\n",
    "yst = scale(yst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear regression - Step, transformed, scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xst, yst, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Create the regressor: reg_step\n",
    "reg_step = LinearRegression()\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "reg_step.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = reg_step.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2 training set: {}\".format(reg_step.score(X_train, y_train)))\n",
    "\n",
    "rmse_step = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error testing set: {}\".format(rmse_step))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 10-fold cross-validation scores: cv_step\n",
    "cv_step = cross_val_score(reg_step, Xst, yst, cv=10)\n",
    "\n",
    "# Print the 10-fold cross-validation scores\n",
    "print(cv_step)\n",
    "\n",
    "print(\"Average 10-Fold CV Score: {}\".format(np.mean(cv_step)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge Regression: Full/transformed data\n",
    "\n",
    "### 1) Determine the best alpha level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the array of alphas and lists to store scores\n",
    "alpha_space = np.logspace(-4, 0, 50)\n",
    "ridge_scores = []\n",
    "ridge_scores_std = []\n",
    "\n",
    "# Create a ridge regressor: ridge\n",
    "ridge = Ridge(normalize=True)\n",
    "\n",
    "# Compute scores over range of alphas\n",
    "for alpha in alpha_space:\n",
    "\n",
    "    # Specify the alpha value to use: ridge.alpha\n",
    "    ridge.alpha = alpha\n",
    "    \n",
    "    # Perform 10-fold CV: ridge_cv_scores\n",
    "    ridge_cv_scores = cross_val_score(ridge, Xft, yft, cv=10)\n",
    "    \n",
    "    # Append the mean of ridge_cv_scores to ridge_scores\n",
    "    ridge_scores.append(np.mean(ridge_cv_scores))\n",
    "    \n",
    "    # Append the std of ridge_cv_scores to ridge_scores_std\n",
    "    ridge_scores_std.append(np.std(ridge_cv_scores))\n",
    "\n",
    "# Display the plot\n",
    "display_plot(ridge_scores, ridge_scores_std)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use 0.08 as before"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Run Ridge regression on full/transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(Xft, yft, test_size = 0.3, random_state=42)\n",
    "\n",
    "# Create the regressor: ridge\n",
    "ridge2 = Ridge(alpha=0.08, normalize=True)\n",
    "\n",
    "# Fit the regressor to the training data\n",
    "ridge2.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "y_pred = ridge2.predict(X_test)\n",
    "\n",
    "# Compute and print R^2 and RMSE\n",
    "print(\"R^2 training set: {}\".format(ridge2.score(X_train, y_train)))\n",
    "rmse_ridge2 = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Root Mean Squared Error testing set: {}\".format(rmse_ridge2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) 10-fold cross-validation:  Ridge on full/transformed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute 10-fold cross-validation scores: cv_ridge2\n",
    "cv_ridge2 = cross_val_score(ridge2, Xft, yft, cv=10)\n",
    "\n",
    "# Print the 10-fold cross-validation scores\n",
    "print(cv_ridge2)\n",
    "\n",
    "print(\"Average 10-Fold CV Score: {}\".format(np.mean(cv_ridge2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONCLUSIONS:  \n",
    "\n",
    "The best R^2 score was with the Ridge regression model with the full, untransformed data (0.57417113). The best RMSE score and the best CV-score were obtained with the Linear regression model with the step-transformed data (0.649084, 0.4530938). Because the purpose of this study is to predict missing values, the Linear regression model with the step-transformed data is the best choice. This model will be used to predict the missing values and produce a completed, estimated map.\n",
    "\n",
    "## Train a final model\n",
    "\n",
    "Run the Linear regresssion model above on the complete step-transformed dataframe: df35"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model_step = model.fit(Xst, yst)\n",
    "\n",
    "print(\"R^2 final model: {}\".format(model_step.score(Xst, yst)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predict missing drug overdose mortality values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read in csv of cleaned data for testing\n",
    "df_test = pd.read_csv('VLynn_DrugOverdose_Test.csv')\n",
    "df35_test = pd.DataFrame(data = df_test, columns = ['aamort', 'chmort', 'infmort', 'mentdistr', 'foodins', 'mvmort',\n",
    "       'uninsure', 'chuninsure', 'disconyouth', 'homicide', 'under18',\n",
    "       'over65', 'aframer', 'amerindian', 'asian', 'hawaiin', 'hispanic',\n",
    "       'rural', 'lifelost', 'fairhealth', 'lowbirth', 'physinactive',\n",
    "       'excdrinking', 'alcoholdrive', 'chlamydia', 'unemployed', 'chpovertyw',\n",
    "       '80income', 'singparent', 'socialassoc', 'severehous', 'commute',\n",
    "       'new_pcp_ratio', 'new_mhp_ratio'])\n",
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Take the log for all the log-normal variables.\n",
    "df35_logtest = pd.DataFrame(data = df35_test, columns = ['aamort', 'chmort', 'infmort', 'mentdistr', 'mvmort', 'homicide',\n",
    "       'over65', 'lifelost', 'fairhealth', 'lowbirth', 'chlamydia',\n",
    "       'singparent', 'severehous', 'new_mhp_ratio'])\n",
    "\n",
    "df35_logtest = np.log(df35_logtest)\n",
    "df35_logtest.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create dataframe of numerical variables that are not log-normal\n",
    "df35_var = pd.DataFrame(data = df35_test, columns =['foodins', 'uninsure', 'chuninsure', 'disconyouth', 'under18',\n",
    "       'aframer', 'amerindian', 'asian', 'hawaiin', 'hispanic', 'rural',\n",
    "       'physinactive', 'excdrinking', 'alcoholdrive', 'unemployed',\n",
    "       'chpovertyw', '80income','socialassoc', 'commute', 'new_pcp_ratio'])\n",
    "\n",
    "#Perform inner join with log-variables\n",
    "left = df35_logtest\n",
    "right = df35_var\n",
    "\n",
    "df_predict = pd.merge(left, right, left_index=True, right_index=True)\n",
    "\n",
    "df_predict[['foodins', 'physinactive','excdrinking', 'commute']] = df_predict[['foodins', 'physinactive','excdrinking', 'commute']].astype(float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Check for infinite values\n",
    "print(df_predict.columns.to_series()[np.isinf(df_predict).any()])\n",
    "print(df_predict.index[np.isinf(df_predict).any(1)])\n",
    "\n",
    "#Replace infinite value with NaN, then fillna with column mean\n",
    "pd.options.mode.use_inf_as_na = True\n",
    "df_predict['singparent'].fillna(df_predict['singparent'].mean(),inplace=True)\n",
    "\n",
    "#Set up variables from testing dataframe: \n",
    "Xpred = df_predict.values\n",
    "\n",
    "#Scale variables\n",
    "Xpred = scale(Xpred)\n",
    "\n",
    "# Predict on the test data: y_pred\n",
    "Ypred = model_step.predict(Xpred)\n",
    "print(type(Ypred))\n",
    "print(len(Ypred))\n",
    "print(Ypred[:15])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Unscale the predicted values\n",
    "mean_of_array = Ypred.mean(axis=0)\n",
    "std_of_array = Ypred.std(axis=0)\n",
    "\n",
    "Yunscaled = (Ypred * std_of_array) + mean_of_array\n",
    "\n",
    "#Unlog the predicted unscaled values\n",
    "predictedY = np.exp(Yunscaled)\n",
    "print(Ypred[:15])\n",
    "print('')\n",
    "print (Yunscaled[:15])\n",
    "print('')\n",
    "print(predictedY[:15])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the series to a dataframe and get summary stats for predicted values\n",
    "df_predY = pd.DataFrame(data = predictedY, columns=['drugmort'])\n",
    "df_predY['drugmort'] = df_predY['drugmort'].round(0)\n",
    "df_predY['drugmort'].describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare to summary stats for training data values\n",
    "df_train = pd.read_csv('VLynn_DrugOverdose_Train.csv')\n",
    "df_train.head()\n",
    "df_train['drugmort'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These look different so I will compare graphically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "from scipy import stats\n",
    "\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.title('Density Plots for Nonpredicted and Predicted Variables',size = 20, y=1.02)\n",
    "sns.kdeplot(df_train['drugmort'], label=\"drugmort unpredicted\")\n",
    "sns.kdeplot(df_predY['drugmort'], label=\"drugmort unpredicted\")\n",
    "plt.xlabel(\"Drug mortality\")\n",
    "\n",
    "plt.legend();\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Join training and testing sets\n",
    "df_test['drugmort'] = df_predY['drugmort']\n",
    "df_joined = pd.concat([df_train, df_test], ignore_index=True)\n",
    "\n",
    "df_joined.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the distribution of predicted values is similar, right skewed with most of the data near the lower end of the values. However, the model made predictions with more values at the extremes. The standard deviations are similar but the predicted values have a lower mean and a much higher maximum values. There are more outliers in the predicted values. This means that most likely the predicted values will be either lower or higher than actual values. \n",
    "\n",
    "There are several things that could be done to improve this model. The first would be to include interaction terms, which were not tested in this study. The second thing would be to consider generalized linear regression models that may better handle this data, as it included variables that were not normally distributed. The last would be to include the Elastic Net in the group of tested models. \n",
    "\n",
    "## Join predicted data to original map data to create predicted map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Read csv with original mapdata: Mapdata.csv\n",
    "df_map = pd.read_csv('Mapdata.csv')\n",
    "df_map.rename(columns={\"State\": \"state\", \"County\": \"county\"}, inplace=True)\n",
    "\n",
    "#Sort both by state and county\n",
    "df_joined.sort_values(['state', 'county'],inplace=True)\n",
    "df_map.sort_values(['state', 'county'],inplace=True)\n",
    "\n",
    "result = pd.merge(df_map, df_joined, how='inner', on=['state', 'county'])\n",
    "result.to_csv('VLynn_DrugOverdose_Finalmap.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
